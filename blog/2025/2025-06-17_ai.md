<!-- Title: AI > GPT -->
<!-- Date: 17/06/2025 -->
<!-- Keywords: AI,ML,ChatGPT,Machine Learning,Overuse,Capitalism -->
<!-- Type: ARTICLE -->

# Ai and its collapse towards GPTS (A Rant) - Shortcomings of LLMs
In this post, I’m going to cover my observations on the commodification and mass exposure of GPT models and how, as a result, other impressive models and AI paradigms are being overshadowed.
What was once a diverse, experimental field is increasingly becoming synonymous with just one architecture: the Generative Pre-trained Transformer as a Large-Language model.

## Artificial Intelligence (AI) and its collapse towards Generative Pre-trained Transformers (GPTs), It’s not all LLMs
AI is more than just language. 
The field was built on decades of work in symbolic reasoning, expert systems, reinforcement learning, computer vision, Bayesian methods, and more. 
But today, mention "AI" and the conversation will inevitably pivot to GPTs. 
This shift, driven by market hype and ease of productization has flattened AI’s rich landscape into a single modality: language generation.

### GPTs are not smart. They are parrots, parrots who have read the entire internet, and then some
Let’s be clear: GPTs are powerful, but they don’t “understand” in the broad human sense, they pattern match (albeit extremly well.)
They are probabilistic pattern machines, predicting what comes next based on vast amounts of data which will have modified the weights and activations of their trillions of parameters inside hundreds or thousands of hidden layers.
That’s not cognition. That’s not reasoning. It’s stochastic mimicry even if very convincing at times. 
But don’t mistake fluency for intelligence, overconfidence in maximising its reward function drives an answer, no matter how wrong, at any cost.

## Novel approaches and The Wall(tm)
I am calling it "The Wall" but realistically I can also see it as the death of intellectualism. 
GPT LLMs are only as "smart" as the data they are trained on. Therefore, people using GPT Models can only ever get to that line, the wall, and not cross it. 
GPT LLMs cannot cross this wall because, as explained above, they cannot think or deduce facts for themselves. 
They cannot understand or attempt novel approaches to problems, they can just repeat what they’ve already seen.

## Machine Learning - Its ML not AI
We keep calling it Artificial Intelligence, but what we’re mostly talking about is Machine Learning: statistical modelling on steroids. 
The “AI” label is a convenient abstraction for business and media, but it distorts public understanding. Calling a chatbot “intelligent” is like calling a microwave “a chef.”

## Business Use - FOMO is not a business strategy
I recently heard that "FOMO is not a business strategy" and I love this phrase. I am seeing a lot of businesses fall towards the "we must use AI everywhere" trope. 
Take for example a Proofing tool for web-to-print software, I can see AI Having some benefits, but I can also see that proven deterministic algorithms have much better outcomes.
There are good use cases for it, summarising emails and extracting key information, Meeting Minutes, Initial Screening for support requests.

This comes with ONE major caveat, don't lapse on security. As McDonalds recently did at time of writing with McHire, their LLM Specialist Hiring Chatbot leaking all 54 Million private chats.
A lot of poeople

## You're using it to do what?! Hallucinations and Inaccuracy
LLMs are unreliable narrators. 
They hallucinate facts, invent citations, and confidently assert nonsense. 
Using them for critical domains, legal advice, medical diagnostics, journalism is not just risky, it's irresponsible. 
We’re still in the early days of aligning these systems with truth.

I've found on several occasions that when I do use it, it invents systems or code that simply does not exist. 
I have had this happen the most with Magento 2 where documentation and semantic versioning are shaky at best.
I have also heard of reports of people writing essays and submitting with citations that either don't exist or are in completely different languages, which in an academic misconduct meeting, they are unable to provide proof of understanding (Although I can see a case of using translation for this purpose).

## SISO - It’s an acronym - google the dead internet theory
SISO: Shit In, Shit Out. As more AI generated content floods the web, future models are increasingly trained on their own reflections. 
The feedback loop is real.
Combine this with the Dead Internet Theory. The idea that much of the web is now generated by bots talking to bots, and you have a recipe for a synthetic, self-referential mess. 
We're building castles on sand.

## This is not a blast, this is simply making an observation
I think GPT LLMs are great if fully understood in how they operate and if the user truly knows their limitations.
Many developers might use them to generate boilerplate code, but they must know that if they want to use a novel tech-stack, a GPT LLM will struggle.

### In a closing remark
AI / ML is powerful, but in the current capitalist-focussed western society, immediate and fast ROI is favoured over actual benefits, even when ROI is not fully understood and it is just manufactured hype. 
Removing the lowest rung and replacing it with  responses from a machine that is having a recognisable impact on global emissions.

Breakthroughs in ML for science, such as non-invasive breast cancer cell classification, 
or monitoring a patient’s vitals, using pattern recognition to assist with patient Observability, allowing potentially life-threatening issues to be caught early should be lifted above just another visual-studio-code fork with another agent cellotaped to it.

